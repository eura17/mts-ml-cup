{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e42086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((414681, 8), (414681, 8), (414681, 8), (414681, 8))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oof_pred = pd.read_csv('./data_mms/fold_preds.csv')\n",
    "oof_pred.drop(['age','fold'], axis=1, inplace=True)\n",
    "oof_pred.columns = ['user_id', 'is_male_proba', 'age_bucket_1_proba', 'age_bucket_2_proba',\n",
    "       'age_bucket_3_proba', 'age_bucket_4_proba', 'age_bucket_5_proba',\n",
    "       'age_bucket_6_proba']\n",
    "\n",
    "test_pred = pd.read_csv('./data_mms/test_preds.csv')\n",
    "test_pred.drop(['age'], axis=1, inplace=True)\n",
    "test_pred.columns = ['user_id', 'is_male_proba', 'age_bucket_1_proba', 'age_bucket_2_proba',\n",
    "       'age_bucket_3_proba', 'age_bucket_4_proba', 'age_bucket_5_proba',\n",
    "       'age_bucket_6_proba']\n",
    "\n",
    "tree_pred = pd.concat([oof_pred,test_pred], copy=False, ignore_index=True).sort_values('user_id').reset_index(drop=True)\n",
    "tree_pred_cols = ['is_male_proba', 'age_bucket_1_proba', 'age_bucket_2_proba',\n",
    "       'age_bucket_3_proba', 'age_bucket_4_proba', 'age_bucket_5_proba',\n",
    "       'age_bucket_6_proba']\n",
    "\n",
    "oof_pred = pd.read_csv('./data_mms/fold_preds-clean.csv')\n",
    "oof_pred.drop(['age','fold'], axis=1, inplace=True)\n",
    "oof_pred.columns = ['user_id', 'is_male_proba_clean', 'age_bucket_1_proba_clean', 'age_bucket_2_proba_clean',\n",
    "       'age_bucket_3_proba_clean', 'age_bucket_4_proba_clean', 'age_bucket_5_proba_clean',\n",
    "       'age_bucket_6_proba_clean']\n",
    "\n",
    "test_pred = pd.read_csv('./data_mms/test_preds-clean.csv')\n",
    "test_pred.drop(['age'], axis=1, inplace=True)\n",
    "test_pred.columns = ['user_id', 'is_male_proba_clean', 'age_bucket_1_proba_clean', 'age_bucket_2_proba_clean',\n",
    "       'age_bucket_3_proba_clean', 'age_bucket_4_proba_clean', 'age_bucket_5_proba_clean',\n",
    "       'age_bucket_6_proba_clean']\n",
    "\n",
    "tree_pred_clean = pd.concat([oof_pred,test_pred], copy=False, ignore_index=True).sort_values('user_id').reset_index(drop=True)\n",
    "tree_pred_clean_cols = ['is_male_proba_clean', 'age_bucket_1_proba_clean', 'age_bucket_2_proba_clean',\n",
    "       'age_bucket_3_proba_clean', 'age_bucket_4_proba_clean', 'age_bucket_5_proba_clean',\n",
    "       'age_bucket_6_proba_clean']\n",
    "\n",
    "tree_pred_clean = tree_pred_clean.groupby('user_id').agg('first').reset_index()\n",
    "\n",
    "oof_pred = pd.read_csv('./data_mms/fold_preds-top.csv')\n",
    "oof_pred.drop(['age','fold'], axis=1, inplace=True)\n",
    "oof_pred.columns = ['user_id', 'is_male_proba_top', 'age_bucket_1_proba_top', 'age_bucket_2_proba_top',\n",
    "       'age_bucket_3_proba_top', 'age_bucket_4_proba_top', 'age_bucket_5_proba_top',\n",
    "       'age_bucket_6_proba_top']\n",
    "\n",
    "test_pred = pd.read_csv('./data_mms/test_preds-top.csv')\n",
    "test_pred.drop(['age'], axis=1, inplace=True)\n",
    "test_pred.columns = ['user_id', 'is_male_proba_top', 'age_bucket_1_proba_top', 'age_bucket_2_proba_top',\n",
    "       'age_bucket_3_proba_top', 'age_bucket_4_proba_top', 'age_bucket_5_proba_top',\n",
    "       'age_bucket_6_proba_top']\n",
    "\n",
    "tree_pred_top = pd.concat([oof_pred,test_pred], copy=False, ignore_index=True).sort_values('user_id').reset_index(drop=True)\n",
    "tree_pred_top_cols = ['is_male_proba_top', 'age_bucket_1_proba_top', 'age_bucket_2_proba_top',\n",
    "       'age_bucket_3_proba_top', 'age_bucket_4_proba_top', 'age_bucket_5_proba_top',\n",
    "       'age_bucket_6_proba_top']\n",
    "\n",
    "tree_pred_top = tree_pred_top.groupby('user_id').agg('first').reset_index()\n",
    "\n",
    "oof_pred = pd.read_csv('./data_mms/fold_preds-bigrams.csv')\n",
    "oof_pred.drop(['age','fold'], axis=1, inplace=True)\n",
    "oof_pred.columns = ['user_id', 'is_male_proba_bigrams', 'age_bucket_1_proba_bigrams', 'age_bucket_2_proba_bigrams',\n",
    "       'age_bucket_3_proba_bigrams', 'age_bucket_4_proba_bigrams', 'age_bucket_5_proba_bigrams',\n",
    "       'age_bucket_6_proba_bigrams']\n",
    "\n",
    "test_pred = pd.read_csv('./data_mms/test_preds-bigrams.csv')\n",
    "test_pred.drop(['age'], axis=1, inplace=True)\n",
    "test_pred.columns = ['user_id', 'is_male_proba_bigrams', 'age_bucket_1_proba_bigrams', 'age_bucket_2_proba_bigrams',\n",
    "       'age_bucket_3_proba_bigrams', 'age_bucket_4_proba_bigrams', 'age_bucket_5_proba_bigrams',\n",
    "       'age_bucket_6_proba_bigrams']\n",
    "\n",
    "tree_pred_bigrams = pd.concat([oof_pred,test_pred], copy=False, ignore_index=True).sort_values('user_id').reset_index(drop=True)\n",
    "tree_pred_bigrams_cols = ['is_male_proba_bigrams', 'age_bucket_1_proba_bigrams', 'age_bucket_2_proba_bigrams',\n",
    "       'age_bucket_3_proba_bigrams', 'age_bucket_4_proba_bigrams', 'age_bucket_5_proba_bigrams',\n",
    "       'age_bucket_6_proba_bigrams']\n",
    "\n",
    "tree_pred_bigrams = tree_pred_bigrams.groupby('user_id').agg('first').reset_index()\n",
    "\n",
    "tree_pred.shape, tree_pred_clean.shape, tree_pred_top.shape, tree_pred_bigrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e12e454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415317, 28)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz \n",
    "from scipy.sparse import coo_matrix\n",
    "import implicit\n",
    "import bisect\n",
    "\n",
    "def age_bucket(x):\n",
    "    return bisect.bisect_left([25,35,45,55,65], x)\n",
    "\n",
    "q = pd.read_parquet('./data_mms/q_f2k_20unk.pq')\n",
    "df_target = pd.read_parquet('./data/public_train.pqt')\n",
    "df_target['real_age'] = df_target['age']\n",
    "q = q.merge(df_target[['user_id','real_age']], on='user_id', how='left')\n",
    "q['age'] = q['real_age'].apply(age_bucket)\n",
    "df_target = df_target.loc[~df_target.isna().any(axis=1)].reset_index(drop=True)\n",
    "\n",
    "q = q.merge(tree_pred, on='user_id', how='left')\n",
    "q = q.merge(tree_pred_clean, on='user_id', how='left')\n",
    "q = q.merge(tree_pred_top, on='user_id', how='left')\n",
    "q = q.merge(tree_pred_bigrams, on='user_id', how='left')\n",
    "user_features = q[tree_pred_cols+tree_pred_clean_cols+tree_pred_top_cols+tree_pred_bigrams_cols].values\n",
    "\n",
    "#user_item = load_npz('./data_mms/ui5.npz')\n",
    "\n",
    "#model = implicit.als.AlternatingLeastSquares(factors=64)\n",
    "#model.fit(user_item)\n",
    "\n",
    "#user_features = model.user_factors.to_numpy()\n",
    "#user_features2 = np.load('./data_mms/uf_svd.npy')\n",
    "#user_features = np.concatenate([user_features, user_features2], axis=1)\n",
    "#user_features = np.zeros((415317, 64))\n",
    "print(user_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6662c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>clean</th>\n",
       "      <th>first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993489</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.997185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigrams</th>\n",
       "      <td>0.993489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993679</td>\n",
       "      <td>0.993218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.993679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.997185</td>\n",
       "      <td>0.993218</td>\n",
       "      <td>0.995834</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              top   bigrams     clean     first\n",
       "top      1.000000  0.993489  0.998200  0.997185\n",
       "bigrams  0.993489  1.000000  0.993679  0.993218\n",
       "clean    0.998200  0.993679  1.000000  0.995834\n",
       "first    0.997185  0.993218  0.995834  1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = pd.DataFrame({\n",
    "    'top': tree_pred_top.is_male_proba_top,\n",
    "    'bigrams': tree_pred_bigrams.is_male_proba_bigrams,\n",
    "    'clean': tree_pred_clean.is_male_proba_clean,\n",
    "    'first': tree_pred.is_male_proba,\n",
    "})\n",
    "q.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdc2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "user_features = ss.fit_transform(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(q.loc[~q['real_age'].isnull()].real_age.values.reshape(-1,1))\n",
    "q['real_age'] = ss.transform(q['real_age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d84a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q['max_url_host'] = q['url_host'].apply(max)\n",
    "#q['max_url_host_last'] = q['url_host_last'].apply(max)\n",
    "#q['max_url_host'].max(), q['max_url_host_last'].max()\n",
    "#(90009, 64278)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7fdc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'region_name', 'city_name', 'cpe_manufacturer_name',\n",
       "       'cpe_model_name', 'url_host', 'cpe_type_cd', 'cpe_model_os_type',\n",
       "       'price', 'part_of_day', 'request_cnt', 'url_host_freq',\n",
       "       'non_digits_cnt', 'new_url_host_freq', 'men_share', 'women_share',\n",
       "       'men_bucket_share_0', 'women_bucket_share_0', 'people_in_bucket_0',\n",
       "       'men_bucket_share_1', 'women_bucket_share_1', 'people_in_bucket_1',\n",
       "       'men_bucket_share_2', 'women_bucket_share_2', 'people_in_bucket_2',\n",
       "       'men_bucket_share_3', 'women_bucket_share_3', 'people_in_bucket_3',\n",
       "       'men_bucket_share_4', 'women_bucket_share_4', 'people_in_bucket_4',\n",
       "       'men_bucket_share_5', 'women_bucket_share_5', 'people_in_bucket_5',\n",
       "       'men_bucket_share_6', 'women_bucket_share_6', 'people_in_bucket_6',\n",
       "       'dow', 'diff_days', 'age', 'is_male', 'real_age', 'is_male_proba',\n",
       "       'age_bucket_1_proba', 'age_bucket_2_proba', 'age_bucket_3_proba',\n",
       "       'age_bucket_4_proba', 'age_bucket_5_proba', 'age_bucket_6_proba',\n",
       "       'is_male_proba_clean', 'age_bucket_1_proba_clean',\n",
       "       'age_bucket_2_proba_clean', 'age_bucket_3_proba_clean',\n",
       "       'age_bucket_4_proba_clean', 'age_bucket_5_proba_clean',\n",
       "       'age_bucket_6_proba_clean', 'is_male_proba_top',\n",
       "       'age_bucket_1_proba_top', 'age_bucket_2_proba_top',\n",
       "       'age_bucket_3_proba_top', 'age_bucket_4_proba_top',\n",
       "       'age_bucket_5_proba_top', 'age_bucket_6_proba_top',\n",
       "       'is_male_proba_bigrams', 'age_bucket_1_proba_bigrams',\n",
       "       'age_bucket_2_proba_bigrams', 'age_bucket_3_proba_bigrams',\n",
       "       'age_bucket_4_proba_bigrams', 'age_bucket_5_proba_bigrams',\n",
       "       'age_bucket_6_proba_bigrams'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c151530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['request_cnt', 'price', 'diff_days', 'men_share', 'women_share', 'men_bucket_share_0',\n",
    "       'women_bucket_share_0', 'people_in_bucket_0', 'men_bucket_share_1',\n",
    "       'women_bucket_share_1', 'people_in_bucket_1', 'men_bucket_share_2',\n",
    "       'women_bucket_share_2', 'people_in_bucket_2', 'men_bucket_share_3',\n",
    "       'women_bucket_share_3', 'people_in_bucket_3', 'men_bucket_share_4',\n",
    "       'women_bucket_share_4', 'people_in_bucket_4', 'men_bucket_share_5',\n",
    "       'women_bucket_share_5', 'people_in_bucket_5', 'men_bucket_share_6',\n",
    "       'women_bucket_share_6', 'people_in_bucket_6']\n",
    "cat_features = ['region_name', 'city_name', 'cpe_manufacturer_name', 'cpe_model_name',\n",
    "                'cpe_type_cd', 'cpe_model_os_type', 'part_of_day', \n",
    "                'url_host','dow'] #\n",
    "cat_embs_size = [(81, 3), (985, 3), (37, 6), (599, 32),\n",
    "                 (4, 2), (3, 2), (4, 2), \n",
    "                 (23761, 200),  (7, 3)] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f278545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class AlphaDataset(Dataset):\n",
    "    def __init__(self, df, is_train = False):\n",
    "        self.df = df.copy()\n",
    "        self.is_train = is_train\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        s = self.df.iloc[idx]\n",
    "        uid = s.user_id\n",
    "        \n",
    "        mask = np.ones(len(s['url_host']))\n",
    "        cat_features_vals = np.stack(s[cat_features].values).T\n",
    "        num_features_vals = np.stack(s[num_features].values).T\n",
    "        user_features_vals = user_features[uid]\n",
    "        if (self.is_train): # and (np.random.rand() > 0.8)\n",
    "            idxs = np.arange(len(s['url_host']))\n",
    "            np.random.shuffle(idxs)\n",
    "            cat_features_vals = cat_features_vals[idxs]\n",
    "            num_features_vals = num_features_vals[idxs]\n",
    "        \n",
    "        targets = [s['age'], s['is_male'],s['real_age']]\n",
    "        return cat_features_vals, num_features_vals,user_features_vals, mask, targets\n",
    "    \n",
    "\n",
    "def pad_matrix(mat, max_len):\n",
    "    n = mat.shape[0]\n",
    "    if len(mat.shape) == 1:\n",
    "        if max_len <= n:\n",
    "            return torch.tensor(mat[-max_len:])\n",
    "        return torch.cat([torch.tensor(mat), torch.zeros(max_len - n)])\n",
    "    if max_len <= n:\n",
    "        return torch.tensor(mat[-max_len:])\n",
    "    return torch.cat([\n",
    "        torch.tensor(mat),\n",
    "        torch.zeros((max_len - n, mat.shape[1]))\n",
    "    ])\n",
    "\n",
    "def collate_batch(batch):\n",
    "    #cat_features_vals, num_features_vals, user_features_vals, mask, targets = batch\n",
    "    max_len = 0\n",
    "    for c in batch:\n",
    "        if c[0].shape[0] > max_len:\n",
    "            max_len = c[0].shape[0]\n",
    "            \n",
    "    if max_len > 1200:\n",
    "        max_len = 1200\n",
    "\n",
    "    return torch.stack([\n",
    "        pad_matrix(m[0], max_len) for m in batch\n",
    "    ]), torch.stack([\n",
    "        pad_matrix(m[1], max_len) for m in batch\n",
    "    ]), torch.stack([\n",
    "        torch.tensor(m[2]) for m in batch\n",
    "    ]), torch.stack([\n",
    "        pad_matrix(m[3], max_len) for m in batch\n",
    "    ]), torch.stack([torch.tensor(m[4]) for m in batch])\n",
    "      \n",
    "#dataloader = DataLoader(ds_test, batch_size=64, collate_fn=collate_batch, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0871aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('./data/submit_2.pqt')\n",
    "test_users = test_df.user_id.unique().tolist()\n",
    "df_test = q.loc[q.user_id.isin(test_users)].reset_index(drop=True)\n",
    "ds_test = AlphaDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fbc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q['data_len'] = q['region_name'].apply(len)\n",
    "#q.loc[q.data_len > 16, 'data_len'] = q.loc[q.data_len > 16, 'url_host_freq'].apply(lambda x: np.where(x < 100000)[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2985c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q['data_len'] = q['region_name'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1c9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class BySequenceLengthSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size=64):\n",
    "        ind_n_len = []\n",
    "        pps = data_source['data_len'].values\n",
    "        for i, p in enumerate(pps):\n",
    "            ind_n_len.append( (i, p) )\n",
    "        self.ind_n_len = ind_n_len\n",
    "        self.bucket_boundaries = np.quantile(pps, [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8])\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        data_buckets = dict()\n",
    "        # where p is the id number and seq_len is the length of this id number. \n",
    "        for p, seq_len in self.ind_n_len:\n",
    "            pid = self.element_to_bucket_id(p,seq_len)\n",
    "            if pid in data_buckets.keys():\n",
    "                data_buckets[pid].append(p)\n",
    "            else:\n",
    "                data_buckets[pid] = [p]\n",
    "\n",
    "        for k in data_buckets.keys():\n",
    "            data_buckets[k] = np.asarray(data_buckets[k])\n",
    "\n",
    "        iter_list = []\n",
    "        for k in data_buckets.keys():\n",
    "            np.random.shuffle(data_buckets[k])\n",
    "            iter_list += (np.array_split(data_buckets[k]\n",
    "                           , int(data_buckets[k].shape[0]/self.batch_size)))\n",
    "        shuffle(iter_list) # shuffle all the batches so they arent ordered by bucket\n",
    "        # size\n",
    "        for i in iter_list: \n",
    "            yield i.tolist() # as it was stored in an array\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_source.shape[0]\n",
    "    \n",
    "    def element_to_bucket_id(self, x, seq_length):\n",
    "        boundaries = list(self.bucket_boundaries)\n",
    "        buckets_min = [np.iinfo(np.int32).min] + boundaries\n",
    "        buckets_max = boundaries + [np.iinfo(np.int32).max]\n",
    "        conditions_c = np.logical_and(\n",
    "          np.less_equal(buckets_min, seq_length),\n",
    "          np.less(seq_length, buckets_max))\n",
    "        bucket_id = np.min(np.where(conditions_c))\n",
    "        return bucket_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6104ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers.models.albert import AlbertConfig, AlbertModel\n",
    "\n",
    "class F1_Loss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred, y_true,):\n",
    "        y_true = F.one_hot(y_true, -1).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        return 1 - f1.mean()\n",
    "\n",
    "class CFG:\n",
    "    learning_rate=1.0e-3\n",
    "    batch_size=64\n",
    "    num_workers=4\n",
    "    print_freq=100\n",
    "    test_freq=1\n",
    "    start_epoch=0\n",
    "    num_train_epochs=3\n",
    "    warmup_steps=30\n",
    "    max_grad_norm=1000\n",
    "    gradient_accumulation_steps=1\n",
    "    weight_decay=0.01    \n",
    "    dropout=0.0\n",
    "    emb_size=100\n",
    "    hidden_size=160\n",
    "    nlayers=2\n",
    "    nheads=8\n",
    "    seq_len=1200\n",
    "    target_size = 7\n",
    "    num_fts_len = 28\n",
    "    fts_len = sum([x[1] for x in cat_embs_size]) + len(num_features)\n",
    "\n",
    "class TransfomerModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(TransfomerModel, self).__init__()\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.embeds = torch.nn.ModuleList([\n",
    "            nn.Embedding(a,b) for a,b in cat_embs_size\n",
    "        ])\n",
    "        \n",
    "        input_len = cfg.fts_len\n",
    "\n",
    "        self.config = AlbertConfig( \n",
    "            3, # not used\n",
    "            embedding_size=input_len,\n",
    "            hidden_size=cfg.hidden_size,\n",
    "            num_hidden_layers=cfg.nlayers,\n",
    "            num_attention_heads=cfg.nheads,\n",
    "            intermediate_size=cfg.hidden_size,            \n",
    "            hidden_dropout_prob=cfg.dropout,\n",
    "            attention_probs_dropout_prob=cfg.dropout,\n",
    "            max_position_embeddings=cfg.seq_len,\n",
    "            type_vocab_size=1,\n",
    "            position_embedding_type = \"relative_key_query\"\n",
    "        )        \n",
    "        self.encoder = AlbertModel(self.config)        \n",
    "        \n",
    "        def get_reg():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(cfg.hidden_size + cfg.num_fts_len, cfg.hidden_size), \n",
    "                nn.LayerNorm(cfg.hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(cfg.hidden_size, cfg.hidden_size),\n",
    "                nn.LayerNorm(cfg.hidden_size),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
    "            ) \n",
    "        self.reg_layer = get_reg() \n",
    "        \n",
    "    def forward(self, cat_features_vals, num_features_vals, user_features_vals, mask):        \n",
    "        batch_size = cat_features_vals.size(0)\n",
    "            \n",
    "        seq_emb = torch.cat([m(cat_features_vals[:,:,i]) \n",
    "                             for i,m in enumerate(self.embeds)] + [num_features_vals], dim=-1)\n",
    "        \n",
    "        seq_length = min(self.cfg.seq_len, cat_features_vals.size(1))\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=cat_features_vals.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand((batch_size, seq_length))\n",
    "        \n",
    "        encoded_layers = self.encoder(inputs_embeds=seq_emb, attention_mask=mask, position_ids=position_ids)\n",
    "        sequence_output = encoded_layers[0]\n",
    "        sequence_output = sequence_output[:, -1]\n",
    "                \n",
    "        x = torch.cat([sequence_output, user_features_vals], dim=1)\n",
    "        #x = sequence_output\n",
    "        \n",
    "        pred_y = self.reg_layer(x)\n",
    "        return pred_y\n",
    "    \n",
    "class AttentionWeightedAverage(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, return_attention: bool = False):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.return_attention = return_attention\n",
    "        \n",
    "        self.attention_vector = nn.Parameter(\n",
    "            torch.empty(self.hidden_dim, dtype=torch.float32),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        nn.init.xavier_normal_(self.attention_vector.unsqueeze(-1))\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, mask: torch.Tensor\n",
    "    ):\n",
    "        logits = x.matmul(self.attention_vector)\n",
    "        ai = (logits - logits.max()).exp()\n",
    "\n",
    "        ai = ai * mask\n",
    "        att_weights = ai / (ai.sum(dim=1, keepdim=True) + 1e-12)\n",
    "        weighted_input = x * att_weights.unsqueeze(-1)\n",
    "        output = weighted_input.sum(dim=1)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return output, att_weights\n",
    "        else:\n",
    "            return output, None\n",
    "    \n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.embeds = torch.nn.ModuleList([\n",
    "            nn.Embedding(a,b) for a,b in cat_embs_size\n",
    "        ])\n",
    "        \n",
    "        input_len = cfg.fts_len\n",
    "\n",
    "        self.encoder = nn.GRU(input_size = cfg.fts_len,\n",
    "                              hidden_size = cfg.hidden_size,\n",
    "                              num_layers = cfg.nlayers,\n",
    "                              batch_first = True,\n",
    "                              bidirectional = True\n",
    "                             )    \n",
    "        #self.atn = AttentionWeightedAverage(2*cfg.hidden_size)\n",
    "        \n",
    "        def get_reg():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(4*cfg.hidden_size + cfg.num_fts_len, cfg.hidden_size), # \n",
    "                nn.LayerNorm(cfg.hidden_size),\n",
    "                nn.Mish(),\n",
    "                #nn.Linear(cfg.hidden_size * 2, cfg.hidden_size),\n",
    "                #nn.LayerNorm(cfg.hidden_size),\n",
    "                #nn.GELU(),\n",
    "                nn.Linear(cfg.hidden_size, cfg.target_size),            \n",
    "            ) \n",
    "        self.reg_layer = get_reg() \n",
    "        \n",
    "    def forward(self, cat_features_vals, num_features_vals, user_features_vals, mask):        \n",
    "        batch_size = cat_features_vals.size(0)\n",
    "            \n",
    "        seq_emb = torch.cat([m(cat_features_vals[:,:,i]) \n",
    "                             for i,m in enumerate(self.embeds)] + [num_features_vals], dim=-1)\n",
    "        \n",
    "        _, sequence_output = self.encoder(seq_emb)\n",
    "        #out, _ = self.atn(out, mask)\n",
    "        sequence_output = sequence_output.transpose(0,1).flatten(start_dim=1)\n",
    "                \n",
    "        x = torch.cat([sequence_output, user_features_vals], dim=1) #\n",
    "        #x = sequence_output\n",
    "        \n",
    "        pred_y = self.reg_layer(x)\n",
    "        return pred_y\n",
    "    \n",
    "class GRUBaseModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(GRUBaseModel, self).__init__()\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.embeds = torch.nn.ModuleList([\n",
    "            nn.Embedding(a,b) for a,b in cat_embs_size\n",
    "        ])\n",
    "        \n",
    "        input_len = cfg.fts_len\n",
    "\n",
    "        self.encoder = nn.GRU(input_size = cfg.fts_len,\n",
    "                              hidden_size = cfg.hidden_size,\n",
    "                              num_layers = cfg.nlayers,\n",
    "                              batch_first = True,\n",
    "                              bidirectional = True\n",
    "                             )            \n",
    "        def get_reg():\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(4*cfg.hidden_size, cfg.hidden_size), \n",
    "                nn.LayerNorm(cfg.hidden_size),\n",
    "                nn.Mish()           \n",
    "            ) \n",
    "        self.reg_layer = get_reg()\n",
    "        self.male_age = nn.Linear(cfg.hidden_size, 7)\n",
    "        self.unsuper  = nn.Linear(cfg.hidden_size, 23761)\n",
    "        \n",
    "    def forward(self, cat_features_vals, num_features_vals):        \n",
    "        batch_size = cat_features_vals.size(0)\n",
    "            \n",
    "        seq_emb = torch.cat([m(cat_features_vals[:,:,i]) \n",
    "                             for i,m in enumerate(self.embeds)] + [num_features_vals], dim=-1)\n",
    "        \n",
    "        _, sequence_output = self.encoder(seq_emb)\n",
    "        sequence_output = sequence_output.transpose(0,1).flatten(start_dim=1)\n",
    "        x = sequence_output\n",
    "        emb = self.reg_layer(x)\n",
    "        \n",
    "        male_age = self.male_age(emb)\n",
    "        unsuper = self.unsuper(emb)\n",
    "        \n",
    "        return male_age, unsuper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39325593",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.loc[(q.is_male == 'NA'), 'is_male'] = '0.5'\n",
    "q['is_male'] = q['is_male'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da0fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score \n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=239)\n",
    "train_users = df_target.loc[(~df_target.is_male.isnull()) & (~df_target.age.isnull())].user_id.values\n",
    "ifold = 0\n",
    "best_metrics = []\n",
    "for tr,va in kf.split(train_users):\n",
    "    print(np.isnan(user_features[train_users[tr].tolist()]).any())\n",
    "    print(np.isnan(user_features[train_users[va].tolist()]).any())\n",
    "    print(np.isnan(user_features[df_test.user_id.values.tolist()]).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7169af32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4761851213736685 0.8857521193907403 1.7238744815288176 1.21263790002891 0.4441967477755887\n",
      "1 0.47354970515897177 0.887224638033483 1.7215486863849094 1.1834414508371127 0.4288298679604417\n",
      "2 0.47957659257284685 0.8870159708632048 1.7331851268721032 1.163975460685435 0.4199622470175936\n",
      "3 0.4753371332086234 0.8849986212685743 1.7206715089543954 1.1439578240116437 0.4100656324199268\n",
      "4 0.47364065132021455 0.8852021610851907 1.7176856248108106 1.120853003788562 0.4009921420897756\n",
      "5 0.4645048433642026 0.881993736909196 1.6929971605467973 1.0973371110501744 0.3912365782651163\n",
      "6 0.4594827227367275 0.8798271995965972 1.6786198446666494 1.0692280298897199 0.38002529383770056\n",
      "0 0.47987979909306333 0.8897663702606027 1.739292338707332 1.2180881300376536 0.4485029490544574\n",
      "2 0.4832967715739721 0.8911643193952573 1.7489221819384588 1.1668649534194737 0.4210154066364634\n",
      "3 0.48206863787601284 0.8875619073616531 1.7392610904753318 1.1476665741646204 0.4110946015483724\n",
      "4 0.4812870752340485 0.8856825910037247 1.7339393324755465 1.124495626705074 0.40093434666036704\n",
      "5 0.4692158737029062 0.8851807991025853 1.708793345610983 1.1006735761011983 0.3907007542672191\n",
      "6 0.46622518071741825 0.8815958540944536 1.6956420696237438 1.0735358620031352 0.38055909615285644\n",
      "0 0.47714671418303783 0.8870191063823868 1.7283316411308491 1.2164852967279318 0.44655568231700854\n",
      "1 0.4834445517355902 0.8872012802449694 1.7412916639611191 1.185071828893882 0.4291036541044215\n",
      "2 0.4713274852759079 0.8858813870396909 1.7144177446311977 1.164834674194686 0.41955083596194886\n",
      "3 0.4736514111386342 0.8863978907531036 1.7200986037834756 1.1435900491099533 0.41031519072274625\n",
      "4 0.4718662207691622 0.8800297217428651 1.7037918850240545 1.121483511023925 0.40020754107488354\n",
      "5 0.4666973678281366 0.8803626554634703 1.6941200465832136 1.096162209493753 0.39068990572842993\n",
      "6 0.452436916542203 0.8784627020264548 1.6617992371373158 1.0698485927871642 0.3799804721351744\n",
      "0 0.48506719755684896 0.887105034010988 1.7443444631356737 1.2182512497163074 0.44603135606387234\n",
      "1 0.48168585420123977 0.8886214970274096 1.7406147024572987 1.1865350828551564 0.4293679189163397\n",
      "2 0.486070073553785 0.8885016324999407 1.7491434121074514 1.1663029205955395 0.4205015787635003\n",
      "3 0.4818645496255842 0.8885505704245198 1.740830240100208 1.146372155580532 0.41112091796332806\n",
      "4 0.4789839230190688 0.8865763559878199 1.7311205580137774 1.1232255897590173 0.40112934115035315\n",
      "5 0.4708777598607576 0.8833349114681404 1.708425342657796 1.0980080349084447 0.39158563289227444\n",
      "6 0.4682079522793105 0.8800902777563065 1.696596460071234 1.0703532395970978 0.3808583923581104\n",
      "0 0.4667931903143802 0.8881152656016353 1.7098169118320312 1.2158555770659192 0.4482159644578438\n",
      "1 0.4704548345888954 0.8890039091448051 1.718917487467401 1.1831614577585523 0.429179970321553\n",
      "2 0.47990141432498373 0.8890669843683735 1.7379367973867144 1.163247141494228 0.4195667895997949\n",
      "3 0.4759981637528345 0.8869488382808934 1.725894004067456 1.142633086663179 0.4097668372263357\n",
      "4 0.4727152732683007 0.8851975084246281 1.7158255633858577 1.1200899606097725 0.40029635350525167\n",
      "5 0.46162445794574086 0.8824948897231736 1.6882386953378288 1.0952598074622035 0.3897023364919303\n",
      "6 0.45911466031034637 0.8800073013003489 1.6782439232213906 1.0678622939305311 0.3789531626029293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score \n",
    "import copy\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=239)\n",
    "train_users = df_target.loc[(~df_target.is_male.isnull()) & (~df_target.age.isnull())].user_id.values\n",
    "ifold = 0\n",
    "best_metrics = []\n",
    "for tr,va in kf.split(train_users):\n",
    "    train_df = q.loc[q.user_id.isin(train_users[tr].tolist())].reset_index(drop=True)\n",
    "    val_df = q.loc[q.user_id.isin(train_users[va].tolist()) & (q.is_male != 0.5)].reset_index(drop=True)\n",
    "    ds_train = AlphaDataset(train_df, is_train = True)\n",
    "    ds_val = AlphaDataset(val_df)\n",
    "    #train_dl = DataLoader(ds_train, batch_size=64, collate_fn=collate_batch, \n",
    "    #                      shuffle=True, num_workers=4)\n",
    "    bs=256\n",
    "    sampler = BySequenceLengthSampler(train_df, bs)\n",
    "    train_dl = DataLoader(ds_train, batch_size=1, \n",
    "                            batch_sampler=sampler, \n",
    "                            num_workers=4,\n",
    "                            collate_fn=collate_batch,\n",
    "                            drop_last=False, \n",
    "                            pin_memory=False)\n",
    "    val_dl = DataLoader(ds_val, batch_size=bs, collate_fn=collate_batch, \n",
    "                        shuffle=False, num_workers=4)\n",
    "\n",
    "    #model = TransfomerModel(CFG).cuda()\n",
    "    model = GRUModel(CFG)\n",
    "    base_model = GRUBaseModel(CFG)\n",
    "    base_model.load_state_dict(torch.load('./ckps_mms/base_model_20_best_st.pth'))\n",
    "    embeds = copy.deepcopy(base_model.embeds.state_dict())\n",
    "    encoder = copy.deepcopy(base_model.encoder.state_dict())\n",
    "    model.embeds.load_state_dict(embeds)\n",
    "    model.encoder.load_state_dict(encoder)\n",
    "    model = model.cuda()\n",
    "    loss1 = torch.nn.CrossEntropyLoss()\n",
    "    loss2 = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-4},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0}\n",
    "        ]\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "                                 optimizer_grouped_parameters,\n",
    "                                 lr=3e-4,\n",
    "                                 weight_decay=CFG.weight_decay, \n",
    "                                 eps=1e-6\n",
    "                                 )\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=CFG.learning_rate)\n",
    "    #optimizer = Lion(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "    \n",
    "    nepochs = 20\n",
    "    steps_per_epoch = 1 + len(ds_train) // 48\n",
    "    nsteps = nepochs * len(ds_train) // 48\n",
    "    warmup_steps = 100 # nepochs * nsteps // 10\n",
    "\n",
    "    best_metric = 0\n",
    "    for epoch in range(7):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        i, l1s, l2s = 0, [], []\n",
    "        for x in train_dl:\n",
    "            out = model(x[0].long().cuda(), x[1].float().cuda(), \n",
    "                        x[2].float().cuda(), x[3].long().cuda())\n",
    "            l2 = loss2(out[:,0], x[4][:,1].float().cuda())\n",
    "            l1 = loss1(out[:,1:], x[4][:,0].long().cuda())\n",
    "            loss = l1 + l2\n",
    "            #print(l1.item(), l2.item())\n",
    "            l1s.append(l1.item())\n",
    "            l2s.append(l2.item())\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "                        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outs, targets = [],[]\n",
    "            for x in val_dl:\n",
    "                out = model(x[0].long().cuda(), x[1].float().cuda(), \n",
    "                            x[2].float().cuda(), x[3].long().cuda())\n",
    "                outs.append(out.detach().cpu().numpy())\n",
    "                targets.append(x[4].detach().cpu().numpy())\n",
    "        outs = np.concatenate(outs, axis=0)\n",
    "        targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "        outs[:,1] = np.argmax(outs[:,1:], axis = 1)\n",
    "        f1_part = f1_score(targets[:,0], outs[:,1], average='weighted')\n",
    "        gini_part = roc_auc_score(targets[:,1].astype(int), outs[:,0])\n",
    "        \n",
    "        new_metric = 2.0*f1_part + (2.0*gini_part - 1.0)\n",
    "        print(epoch, f1_part, gini_part, new_metric, np.mean(l1s), np.mean(l2s))\n",
    "        if new_metric > best_metric:\n",
    "            best_metric = new_metric\n",
    "            torch.save(model.state_dict(), f'./ckps_mms/msh_nn_st6{ifold}.pth')\n",
    "    best_metrics.append(best_metric)\n",
    "    ifold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4d5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71adb8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7420958364531693,\n",
       " [1.7331851268721032,\n",
       "  1.7489221819384588,\n",
       "  1.7412916639611191,\n",
       "  1.7491434121074514,\n",
       "  1.7379367973867144])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(best_metrics), best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7446a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [12:17<00:00, 73.80s/it]\n",
      "100%|██████████| 10/10 [12:18<00:00, 73.84s/it]\n",
      "100%|██████████| 10/10 [12:18<00:00, 73.83s/it]\n",
      "100%|██████████| 10/10 [12:18<00:00, 73.89s/it]\n",
      "100%|██████████| 10/10 [12:19<00:00, 73.96s/it]\n"
     ]
    }
   ],
   "source": [
    "def np_sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def test_collate_batch(batch):\n",
    "    #cat_features_vals, num_features_vals, user_features_vals, mask, targets = batch\n",
    "    max_len = 0\n",
    "    for c in batch:\n",
    "        if c[0].shape[0] > max_len:\n",
    "            max_len = c[0].shape[0]\n",
    "            \n",
    "    if max_len > 1200:\n",
    "        max_len = 1200\n",
    "\n",
    "    return torch.stack([\n",
    "        pad_matrix(m[0], max_len) for m in batch\n",
    "    ]), torch.stack([\n",
    "        pad_matrix(m[1], max_len) for m in batch\n",
    "    ]), torch.stack([\n",
    "        torch.tensor(m[2]) for m in batch\n",
    "    ]), torch.stack([\n",
    "        pad_matrix(m[3], max_len) for m in batch\n",
    "    ])\n",
    "      \n",
    "total_outs = np.zeros((50,len(ds_test),7))\n",
    "\n",
    "for i in range(5):\n",
    "    model.load_state_dict(torch.load(f'./ckps_mms/msh_nn_st6{i}.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    for j in tqdm.tqdm(range(10)):\n",
    "        ds_test = AlphaDataset(df_test, is_train=True)\n",
    "        test_dl = DataLoader(ds_test, batch_size=256, \n",
    "                             collate_fn=test_collate_batch, \n",
    "                             shuffle=False, num_workers=4)\n",
    "        with torch.no_grad():\n",
    "            outs = []\n",
    "            for x in test_dl:\n",
    "                out = model(x[0].long().cuda(), x[1].float().cuda(), \n",
    "                            x[2].float().cuda(), x[3].long().cuda())\n",
    "                outs.append(out.detach().cpu().numpy())\n",
    "        outs = np.concatenate(outs, axis=0)\n",
    "        total_outs[i*10+j] = outs\n",
    "    \n",
    "outs = np.mean(total_outs, axis=0)\n",
    "\n",
    "df_test['age'] = np.argmax(outs[:,1:], axis = 1) + 1\n",
    "df_test['is_male'] = np_sigmoid(outs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1683169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>region_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>cpe_manufacturer_name</th>\n",
       "      <th>cpe_model_name</th>\n",
       "      <th>url_host</th>\n",
       "      <th>cpe_type_cd</th>\n",
       "      <th>cpe_model_os_type</th>\n",
       "      <th>price</th>\n",
       "      <th>part_of_day</th>\n",
       "      <th>...</th>\n",
       "      <th>age_bucket_4_proba_top</th>\n",
       "      <th>age_bucket_5_proba_top</th>\n",
       "      <th>age_bucket_6_proba_top</th>\n",
       "      <th>is_male_proba_bigrams</th>\n",
       "      <th>age_bucket_1_proba_bigrams</th>\n",
       "      <th>age_bucket_2_proba_bigrams</th>\n",
       "      <th>age_bucket_3_proba_bigrams</th>\n",
       "      <th>age_bucket_4_proba_bigrams</th>\n",
       "      <th>age_bucket_5_proba_bigrams</th>\n",
       "      <th>age_bucket_6_proba_bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, region_name, city_name, cpe_manufacturer_name, cpe_model_name, url_host, cpe_type_cd, cpe_model_os_type, price, part_of_day, request_cnt, url_host_freq, non_digits_cnt, new_url_host_freq, men_share, women_share, men_bucket_share_0, women_bucket_share_0, people_in_bucket_0, men_bucket_share_1, women_bucket_share_1, people_in_bucket_1, men_bucket_share_2, women_bucket_share_2, people_in_bucket_2, men_bucket_share_3, women_bucket_share_3, people_in_bucket_3, men_bucket_share_4, women_bucket_share_4, people_in_bucket_4, men_bucket_share_5, women_bucket_share_5, people_in_bucket_5, men_bucket_share_6, women_bucket_share_6, people_in_bucket_6, dow, diff_days, age, is_male, real_age, is_male_proba, age_bucket_1_proba, age_bucket_2_proba, age_bucket_3_proba, age_bucket_4_proba, age_bucket_5_proba, age_bucket_6_proba, is_male_proba_clean, age_bucket_1_proba_clean, age_bucket_2_proba_clean, age_bucket_3_proba_clean, age_bucket_4_proba_clean, age_bucket_5_proba_clean, age_bucket_6_proba_clean, is_male_proba_top, age_bucket_1_proba_top, age_bucket_2_proba_top, age_bucket_3_proba_top, age_bucket_4_proba_top, age_bucket_5_proba_top, age_bucket_6_proba_top, is_male_proba_bigrams, age_bucket_1_proba_bigrams, age_bucket_2_proba_bigrams, age_bucket_3_proba_bigrams, age_bucket_4_proba_bigrams, age_bucket_5_proba_bigrams, age_bucket_6_proba_bigrams]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 70 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[df_test[['user_id','age','is_male']].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2ef6c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.231073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.907542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.918913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age   is_male\n",
       "0        6    2  0.231073\n",
       "1        7    2  0.907542\n",
       "2        9    1  0.070465\n",
       "3       10    3  0.025942\n",
       "4       11    5  0.918913"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['user_id','age','is_male']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab6a49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    51676\n",
       "3    50783\n",
       "4    17464\n",
       "1    13458\n",
       "5    11161\n",
       "6      182\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f95ed1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['user_id','age','is_male']].to_csv('nn_st6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04e52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
