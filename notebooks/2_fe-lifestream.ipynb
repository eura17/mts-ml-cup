{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdfc771-6739-41dc-a79c-81f3ea0e8473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ababkin/.cache/pypoetry/virtualenvs/mts-ml-cup-qFoUb2su-py3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import polars\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mts_ml_cup.utils import polars_map\n",
    "from mts_ml_cup.preprocessing import urls as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916c07f3-f5e6-437c-b8be-eca23536ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 s, sys: 15.3 s, total: 1min 14s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = polars.read_parquet(\"../data/processed/sessions.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25643c79-ad9c-478d-aed8-50c3643d41fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4380d0a8-4b11-4f0d-81a0-86f16a489b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 26.2 s, total: 2min 5s\n",
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url_cleaner = partial(\n",
    "    u.clean_url,\n",
    "    preprocessors=[\n",
    "        u.decode_from_punycode,\n",
    "        u.lower,\n",
    "        u.replace_hyphens_with_dots,\n",
    "    ],\n",
    ")\n",
    "urls_mapping = (\n",
    "    df\n",
    "    .select(\"url_host\")\n",
    "    .unique()\n",
    "    .with_columns(polars.col(\"url_host\").apply(url_cleaner).alias(\"url_cleaned\"))\n",
    "    .with_columns(polars.col(\"url_cleaned\").rank(method=\"dense\").alias(\"url_id\"))\n",
    "    .select([\"url_host\", \"url_id\"])\n",
    "    .to_pandas()\n",
    "    .set_index(\"url_host\")[\"url_id\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "dates = df[\"date\"].unique()\n",
    "dates_mapping = dict(zip(sorted(dates), range(1, len(dates) + 1)))\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .join(\n",
    "        other=polars_map(\n",
    "            mapping=urls_mapping,\n",
    "            key_name=\"url_host\",\n",
    "            id_name=\"url_id\",\n",
    "            id_dtype=polars.UInt32,\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=\"url_host\",\n",
    "    )\n",
    "    .join(\n",
    "        other=polars_map(\n",
    "            mapping=dates_mapping,\n",
    "            key_name=\"date\",\n",
    "            id_name=\"date_id\",\n",
    "            id_dtype=polars.UInt16,\n",
    "        ),\n",
    "        how=\"left\",\n",
    "        on=\"date\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00099d77-a9e3-4eff-8a6d-355da47eecaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(range(10), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f113d4a9-4ebe-45ab-9ffd-17d09eaf17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = df[\"user_id\"].value_counts()[\"counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce66ae4-09ff-4845-8bb6-d67e8352dbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;min&quot;</td><td>1.0</td></tr><tr><td>&quot;max&quot;</td><td>29596.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>777.477048</td></tr><tr><td>&quot;std&quot;</td><td>1034.880997</td></tr><tr><td>&quot;count&quot;</td><td>415317.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 2)\n",
       "┌────────────┬─────────────┐\n",
       "│ statistic  ┆ value       │\n",
       "│ ---        ┆ ---         │\n",
       "│ str        ┆ f64         │\n",
       "╞════════════╪═════════════╡\n",
       "│ min        ┆ 1.0         │\n",
       "│ max        ┆ 29596.0     │\n",
       "│ null_count ┆ 0.0         │\n",
       "│ mean       ┆ 777.477048  │\n",
       "│ std        ┆ 1034.880997 │\n",
       "│ count      ┆ 415317.0    │\n",
       "└────────────┴─────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlen.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c7652e-73b1-4186-857c-404ad572ec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqlen.to_pandas().plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf0db0c-e2a4-4d61-9f7b-f126f294f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 21.0\n",
      "0.2 68.0\n",
      "0.3 151.0\n",
      "0.4 268.0\n",
      "0.5 421.0\n",
      "0.6 617.0\n",
      "0.7 883.0\n",
      "0.8 1269.0\n",
      "0.9 1962.0\n"
     ]
    }
   ],
   "source": [
    "for q in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    print(q, seqlen.quantile(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd24ed91-34a8-48b0-9aaf-0c6a1ca569b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['region_id'].n_unique() = 81\n",
      "df['city_id'].n_unique() = 1000\n",
      "df['manufacturer_id'].n_unique() = 31\n",
      "df['model_id'].n_unique() = 603\n",
      "df['type_id'].n_unique() = 4\n",
      "df['os_id'].n_unique() = 2\n",
      "df['date_id'].n_unique() = 396\n",
      "df['part_of_day_id'].n_unique() = 4\n",
      "df['url_id'].n_unique() = 199508\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"{df['region_id'].n_unique() = }\\n\"\n",
    "    f\"{df['city_id'].n_unique() = }\\n\"\n",
    "    \n",
    "    f\"{df['manufacturer_id'].n_unique() = }\\n\"\n",
    "    f\"{df['model_id'].n_unique() = }\\n\"\n",
    "    f\"{df['type_id'].n_unique() = }\\n\"\n",
    "    f\"{df['os_id'].n_unique() = }\\n\"\n",
    "    \n",
    "    f\"{df['date_id'].n_unique() = }\\n\"\n",
    "    f\"{df['part_of_day_id'].n_unique() = }\\n\"\n",
    "    f\"{df['url_id'].n_unique() = }\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b2f5ab-390b-451b-9673-d1d1509215d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_for_ptls(df: polars.DataFrame) -> dict[str, torch.Tensor]:\n",
    "    dataset = []\n",
    "    for user_id, user_df in tqdm(df.groupby(\"user_id\"), total=df[\"user_id\"].n_unique()):\n",
    "        user_df = user_df.sort([\"date\", \"part_of_day_id\"])\n",
    "        user_encoded = {\n",
    "            \"user_id\": user_id,\n",
    "            \"region_id\": torch.from_numpy(user_df[\"region_id\"].to_numpy()),\n",
    "            \n",
    "            \"city_id\": torch.from_numpy(user_df[\"city_id\"].to_numpy().astype(\"int16\")),\n",
    "            \"manufacturer_id\": torch.from_numpy(user_df[\"manufacturer_id\"].to_numpy()),\n",
    "            \"model_id\": torch.from_numpy(user_df[\"model_id\"].to_numpy().astype(\"int16\")),\n",
    "            \"type_id\": torch.from_numpy(user_df[\"type_id\"].to_numpy()),\n",
    "            \"os_id\": torch.from_numpy(user_df[\"os_id\"].to_numpy()),\n",
    "            \n",
    "            \"event_time\": torch.tensor(range(1, len(user_df) + 1)),\n",
    "            \"date_id\": torch.from_numpy(user_df[\"date_id\"].to_numpy().astype(\"int16\")),\n",
    "            \"part_of_day_id\": torch.from_numpy(user_df[\"part_of_day_id\"].to_numpy()),\n",
    "            \"url_id\": torch.from_numpy(user_df[\"url_id\"].to_numpy().astype(\"int32\")),\n",
    "            \"request_cnt\": torch.from_numpy(user_df[\"request_cnt\"].to_numpy()),\n",
    "        }\n",
    "        dataset.append(user_encoded)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "336c993c-4520-49a1-af12-d6e814727c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                | 0/415317 [00:00<?, ?it/s]/tmp/ipykernel_956018/824887297.py:7: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  \"region_id\": torch.from_numpy(user_df[\"region_id\"].to_numpy()),\n",
      "100%|██████████████████████████████████| 415317/415317 [08:08<00:00, 851.01it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_for_ptls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd11df7-70f7-4cd2-8075-ea73a0b8ce25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 15s, sys: 13.9 s, total: 3min 29s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(dataset, \"../data/ptls-v3/dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d4e13c3-57e8-4df7-82e6-894b80a0876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 305 ms, total: 4.19 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(dataset[:10_000], \"../data/ptls-v3/dataset-sample.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "633192ca-4649-48ad-8ede-e36ceb6b00c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8.6G\n",
      "-rw-rw-r-- 1 ababkin ababkin 8.4G Mar 22 16:34 dataset.pt\n",
      "-rw-rw-r-- 1 ababkin ababkin 200M Mar 22 17:10 dataset-sample.pt\n"
     ]
    }
   ],
   "source": [
    "! ls -lh ../data/ptls-v3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37857b3-4361-480d-9243-5206cc9e1e55",
   "metadata": {},
   "source": [
    "# Fit self-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7e20db-6b03-4be6-a8c0-13332ffb8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 15.6 s, total: 3min 1s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = torch.load(\"../data/ptls-v3/dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4383946-05dd-4321-ad5b-c85646c14bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4a145f-ae31-4d96-b8d8-d9df3cc7a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(\n",
    "        embeddings={\n",
    "            \"region_id\": {\"in\": 81, \"out\": 4},\n",
    "            \"city_id\": {\"in\": 1_000, \"out\": 8},\n",
    "            \n",
    "            \"manufacturer_id\": {\"in\": 31, \"out\": 4},\n",
    "            \"model_id\": {\"in\": 603, \"out\": 8},\n",
    "            \"type_id\": {\"in\": 4, \"out\": 1},\n",
    "            \"os_id\": {\"in\": 2, \"out\": 1},\n",
    "            \n",
    "            \"date_id\": {\"in\": 396, \"out\": 8},\n",
    "            \"part_of_day_id\": {\"in\": 4, \"out\": 2},\n",
    "            \"url_id\": {\"in\": 199508, \"out\": 128},\n",
    "        },\n",
    "        embeddings_noise=0.003,\n",
    "        numeric_values={\n",
    "            \"request_cnt\": \"log\",\n",
    "        },\n",
    "        use_batch_norm_with_lens=True,\n",
    "        orthogonal_init=True,\n",
    "    ),\n",
    "    hidden_size=256,\n",
    "    type=\"gru\",\n",
    ")\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(\n",
    "        torch.optim.lr_scheduler.OneCycleLR,\n",
    "        max_lr=1e-3,\n",
    "        total_steps=146_800, epochs=100, steps_per_epoch=1468,\n",
    "        pct_start=0.3, anneal_strategy=\"cos\",\n",
    "        cycle_momentum=True, base_momentum=0.85, max_momentum=0.95,\n",
    "        div_factor=25.0, final_div_factor=10_000.0, three_phase=False,\n",
    "        last_epoch=-1, verbose=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a0dca2-cc26-4958-8783-72447d22084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25878600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in seq_encoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f28c1c3-9d5b-464d-a94a-82b826ea49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices, SampleRandom\n",
    "from ptls.frames import PtlsDataModule\n",
    "\n",
    "train_dl = PtlsDataModule(\n",
    "    train_data=ColesDataset(\n",
    "        MemoryMapDataset(\n",
    "            data=dataset,\n",
    "            i_filters=[\n",
    "                SeqLenFilter(min_seq_len=20)\n",
    "            ]\n",
    "        ),\n",
    "        splitter=SampleRandom(\n",
    "            split_count=5,\n",
    "            cnt_min=100,\n",
    "            cnt_max=300,\n",
    "        ),\n",
    "    ),\n",
    "    train_num_workers=0,\n",
    "    train_batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7208abf-e116-401a-93b0-57f09f1fdf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    enable_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0071727-a309-4e3d-9484-bd6a4f8067d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ababkin/.cache/pypoetry/virtualenvs/mts-ml-cup-qFoUb2su-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type            | Params\n",
      "-------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0     \n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 25.9 M\n",
      "2 | _validation_metric | BatchRecallTopK | 0     \n",
      "3 | _head              | Head            | 0     \n",
      "-------------------------------------------------------\n",
      "25.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.9 M    Total params\n",
      "103.514   Total estimated model params size (MB)\n",
      "/home/ababkin/.cache/pypoetry/virtualenvs/mts-ml-cup-qFoUb2su-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  88%|▉| 1296/1468 [10:14<01:21,  2.11it/s, loss=10, v_num=27, seq_len="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:  38%|▍| 560/1468 [04:27<07:13,  2.09it/s, loss=8.76, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  77%|▊| 1133/1468 [08:55<02:38,  2.12it/s, loss=8.19, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23:  28%|▎| 407/1468 [03:13<08:24,  2.11it/s, loss=8.52, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:  79%|▊| 1166/1468 [09:11<02:22,  2.12it/s, loss=9.67, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28:  15%|▏| 218/1468 [01:43<09:52,  2.11it/s, loss=6.92, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30:  62%|▌| 909/1468 [07:09<04:23,  2.12it/s, loss=9.32, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33:   7%| | 102/1468 [00:50<11:20,  2.01it/s, loss=6.29, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  49%|▍| 724/1468 [05:41<05:50,  2.12it/s, loss=7.47, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  80%|▊| 1179/1468 [09:20<02:17,  2.10it/s, loss=6.7, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40:  20%|▏| 299/1468 [02:20<09:08,  2.13it/s, loss=7.3, v_num=27, seq_len="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42:  65%|▋| 957/1468 [07:36<04:03,  2.10it/s, loss=7.06, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45:  10%| | 150/1468 [01:08<09:58,  2.20it/s, loss=6.51, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:  18%|▏| 271/1468 [02:07<09:23,  2.13it/s, loss=5.94, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47:  54%|▌| 800/1468 [06:20<05:17,  2.10it/s, loss=6.15, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55:  80%|▊| 1168/1468 [09:11<02:21,  2.12it/s, loss=6.72, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58:  30%|▎| 446/1468 [03:34<08:10,  2.08it/s, loss=7.21, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60:  74%|▋| 1091/1468 [08:36<02:58,  2.11it/s, loss=6.33, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63:  22%|▏| 319/1468 [02:33<09:13,  2.08it/s, loss=6.52, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82:  80%|▊| 1175/1468 [09:18<02:19,  2.10it/s, loss=4.94, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85:  26%|▎| 387/1468 [03:04<08:34,  2.10it/s, loss=6.82, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87:  38%|▍| 559/1468 [04:27<07:14,  2.09it/s, loss=6.18, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89:  90%|▉| 1326/1468 [10:32<01:07,  2.09it/s, loss=5.91, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91:  92%|▉| 1346/1468 [10:37<00:57,  2.11it/s, loss=6.03, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94:  37%|▎| 544/1468 [04:21<07:23,  2.08it/s, loss=6.72, v_num=27, seq_len"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:  86%|▊| 1267/1468 [10:02<01:35,  2.10it/s, loss=5.82, v_num=27, seq_le"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|█| 1468/1468 [11:39<00:00,  2.10it/s, loss=5.3, v_num=27, seq_len\n",
      "{'loss': tensor(0.3499), 'seq_len': tensor(164.6765)}\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56fe905f-283b-4d3e-9868-2ce6407f86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.3499), 'seq_len': tensor(164.6765)}\n"
     ]
    }
   ],
   "source": [
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb24ce-088a-43d6-b43c-0f52000eb1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748d0ec-4dae-49e6-900f-0b652eea89a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47ad27-ff17-42b8-94d7-7b285db1929e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3b54d-8055-4f60-8e71-0ec9f6bb995f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f29f3e-f7e1-4c8f-9cd1-357e1e61f21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 ms, sys: 80.2 ms, total: 121 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(seq_encoder, \"../data/ptls-v3/seq-encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3f013c9-d917-4609-8fc9-e07b3d6c4e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 7s, sys: 15.8 s, total: 3min 23s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(model, \"../data/ptls-v3/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93947c87-b4fd-4afa-a006-28e3e1bd49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import inference_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3834e654-4afe-4982-8524-862e118fd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dl = inference_data_loader(dataset, num_workers=0, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4dcd07-94fd-43ed-83f4-222c800de74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0dfb733-bef6-46ff-b87f-8e1c2a5e3b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ababkin/.cache/pypoetry/virtualenvs/mts-ml-cup-qFoUb2su-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: : 0it [00:00, -1501765.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ababkin/.cache/pypoetry/virtualenvs/mts-ml-cup-qFoUb2su-py3.8/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:175: UserWarning: Lightning couldn't infer the indices fetched for your dataloader.\n",
      "  warning_cache.warn(\"Lightning couldn't infer the indices fetched for your dataloader.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: : 1623it [07:51,  3.04s/it]   \n",
      "CPU times: user 7min 59s, sys: 1min 16s, total: 9min 16s\n",
      "Wall time: 7min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([415317, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "coles_embs = torch.vstack(trainer.predict(model, inference_dl))\n",
    "coles_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2975bd02-22d7-4e54-82e4-d3df0806404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(coles_embs, \"../data/ptls-v3/embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec44208-67ff-4eca-96db-2539b997ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = [d[\"user_id\"] for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0858ce21-2040-4573-a764-a7e57c0654e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ptls-v3/user_ids-long.jbl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib as jbl\n",
    "jbl.dump(user_ids, \"../data/ptls-v3/user_ids-long.jbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ebf0375-b521-4a46-9cf0-2113f626f68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 2.15 s, total: 13.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "embs = pd.DataFrame()\n",
    "embs[\"user_id\"] = user_ids\n",
    "embs[\"ptls_embeddings\"] = pd.DataFrame(coles_embs.numpy()).apply(lambda x: x.tolist(), axis=1)\n",
    "embs = (\n",
    "    polars.from_pandas(embs)\n",
    "    .with_columns(polars.col(\"ptls_embeddings\").cast(polars.List(polars.Float32)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a2952fa-fd2d-449a-b39c-e86e6483e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.write_parquet(\"../data/features/ptls/embs-long.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb371a-58da-4f10-a06e-0ecbe74a324a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mts-ml-cup)",
   "language": "python",
   "name": "mts-ml-cup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
